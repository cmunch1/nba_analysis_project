# PyTorch baseline hyperparameters
learning_rate: 0.001
weight_decay: 1.0e-5
dropout_rate: 0.2
batch_size: 64
epochs: 100
early_stopping_patience: 10
hidden_sizes:
  - 128
  - 64
  - 32
optimizer: adam
momentum: 0.9
random_state: 42

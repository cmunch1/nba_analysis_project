# Optuna optimization settings
optuna:
  n_trials: 10
  scoring: auc
  direction: maximize
  pruner: 'median'  # Available: 'median', 'hyperband', 'threshold'
  n_startup_trials: 5
  n_warmup_steps: 5
  interval_steps: 1

# XGBoost parameter space
xgb_param_space:
  static_params:
    verbosity: 0
    device: cuda
    random_state: 42
    objective: binary:logistic
    eval_metric: auc
    tree_method: hist

  dynamic_params:
    learning_rate: [1.0e-3, 1.0, float, true]  # true for log scale
    max_bin: [2, 256, int]
    max_depth: [1, 15, int]
    alpha: [1.0e-16, 12, float, true]
    gamma: [1.0e-16, 12, float, true]
    reg_lambda: [1.0e-16, 12, float, true]
    colsample_bytree: [1.0e-16, 1.0, float, true]
    subsample: [1.0e-16, 1.0, float, true]
    min_child_weight: [1.0e-16, 12, float, true]
    scale_pos_weight: [1, 15, int] # may need to higher for imbalanced data

# LightGBM parameter space
lgbm_param_space:
  static_params:
    objective: binary
    metric: auc
    verbosity: -1

  dynamic_params:
    num_leaves: [2, 128, int]
    learning_rate: [1.0e-3, 1.0, float, true]
    feature_fraction: [0.1, 1.0, float]
    bagging_fraction: [0.1, 1.0, float]
    min_child_samples: [5, 100, int]
    max_depth: [3, 15, int]
    lambda_l1: [1e-8, 10.0, float, true]
    lambda_l2: [1e-8, 10.0, float, true]
    min_split_gain: [0.0, 1.0, float]
    bagging_freq: [1, 10, int]

# CatBoost parameter space  
catboost_param_space:
 static_params:
   loss_function: Logloss
   eval_metric: AUC
   task_type: GPU
   verbose: False
 dynamic_params:
   learning_rate: [1e-3, 1.0, float, true]
   depth: [3, 10, int] 
   l2_leaf_reg: [1e-8, 10, float, true]
   random_strength: [1e-8, 10, float, true]
   bagging_temperature: [0, 10, float]
   min_data_in_leaf: [1, 50, int]
   leaf_estimation_iterations: [1, 15, int]

# HistGradientBoosting parameter space
hist_param_space:
 static_params:
   loss: binary_crossentropy
   scoring: roc_auc
 dynamic_params:
   learning_rate: [1e-3, 1.0, float, true]
   max_leaf_nodes: [3, 255, int]
   max_depth: [3, 15, int]
   min_samples_leaf: [5, 100, int]
   l2_regularization: [1e-8, 10, float, true]
   max_bins: [10, 255, int]

# Random Forest parameter space  
rf_param_space:
 static_params:
   n_jobs: -1
   random_state: 42
 dynamic_params:
   n_estimators: [50, 500, int]
   max_depth: [3, 20, int]
   min_samples_split: [2, 20, int]
   min_samples_leaf: [1, 10, int]
   max_features: [0.1, 1.0, float]
   bootstrap: [true, false]

# Logistic Regression parameter space
lr_param_space:
 static_params:
   random_state: 42
   n_jobs: -1
 dynamic_params:
   C: [1e-4, 1e4, float, true]
   max_iter: [100, 1000, int]
   l1_ratio: [0, 1, float]  # For elastic net
   penalty: ['l1', 'l2', 'elasticnet']
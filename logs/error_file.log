{"timestamp": 1724595674.1630023, "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "e3cf6e2b-9160-4159-a5f3-14ea88bd98bf"}
{"timestamp": 1724598334.1091247, "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "6d8559fc-c45f-4ffa-9e13-c8a6e9cf8733"}
{"timestamp": 1724598788.9599376, "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"timestamp\": \"2024-08-25T10:13:08.959937\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "ca1b2f45-bd4d-4347-9d23-66abb02a5ef2"}
{"timestamp": "2024-08-25T15:21:42.422646+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "8abd7d4a-8ed6-4eaa-81a6-29dd7eb9b0df"}
{"timestamp": "2024-08-25T15:59:58.871147+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 136, in handle_pagination\\n    pagination = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, pagination_class)))\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00228923+23283]\\n\\t(No symbol) [0x001EE934]\\n\\t(No symbol) [0x00120733]\\n\\t(No symbol) [0x0016326F]\\n\\t(No symbol) [0x001634AB]\\n\\t(No symbol) [0x0019EE42]\\n\\t(No symbol) [0x00184464]\\n\\t(No symbol) [0x0019CB8D]\\n\\t(No symbol) [0x001841B6]\\n\\t(No symbol) [0x00158017]\\n\\t(No symbol) [0x0015890D]\\n\\tGetHandleVerifier [0x0031A5F3+1013699]\\n\\tGetHandleVerifier [0x00323E4C+1052700]\\n\\tGetHandleVerifier [0x0031D4B4+1025668]\\n\\tGetHandleVerifier [0x0024EA2B+179195]\\n\\t(No symbol) [0x001F6833]\\n\\t(No symbol) [0x001F3198]\\n\\t(No symbol) [0x001F3337]\\n\\t(No symbol) [0x001EB4BE]\\n\\tBaseThreadInitThunk [0x7527FCC9+25]\\n\\tRtlGetAppContainerNamedObjectPath [0x76F280CE+286]\\n\\tRtlGetAppContainerNamedObjectPath [0x76F2809E+238]\\n\\t(No symbol) [0x00000000]\\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 222, in scrape_page_table\\n    self.handle_pagination(pagination_class, dropdown_class)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 154, in handle_pagination\\n    raise ElementNotFoundError(\\\"No pagination found on the page\\\")\\nsrc.error_handling.custom_exceptions.ElementNotFoundError: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 289, in scrape_boxscores_table\\n    raise ScrapingError(f\\\"Error scraping table: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\"}", "error_id": "10b70635-0d10-4d07-a3fe-08547a0e7849"}
{"timestamp": "2024-08-25T17:23:18.071518+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 112, in go_to_url\\n    self.web_driver.set_page_load_timeout(self.config.page_load_timeout)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 267, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 136, in go_to_url\\n    raise PageLoadError(f\\\"Error navigating to {url}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\"}", "error_id": "cc962a7e-f883-42c8-939d-2e4c647f422e"}
{"timestamp": "2024-08-25T17:26:57.303641+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 112, in go_to_url\\n    self.web_driver.set_page_load_timeout(self.config.page_load_timeout)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 267, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 136, in go_to_url\\n    raise PageLoadError(f\\\"Error navigating to {url}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\"}", "error_id": "7d045a54-45ac-49f3-b59b-f10c7edc4e8f"}
{"timestamp": "2024-08-25T17:29:46.265221+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 269, in scrape_page_table\\n    raise PageLoadError(f\\\"Could not navigate to URL: {url}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\"}", "error_id": "a62d375a-3345-4fb0-a965-6eb9024cb730"}
{"timestamp": "2024-08-25T18:05:49.697041+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 287, in scrape_page_table\\n    raise PageLoadError(f\\\"Could not navigate to URL: {url}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\"}", "error_id": "e6959f32-9aad-47b1-bddb-97ec64d26168"}
{"timestamp": "2024-08-25T18:46:56.073637+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 117, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 279, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 125, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "824619c1-6535-4f6e-bd3b-65dd330f711b"}
{"timestamp": "2024-08-26T12:44:06.026752+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "23e694cf-78a9-4a00-9677-0a21c20f47ff"}
{"timestamp": "2024-08-27T12:09:02.236253+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "045d2716-5331-450f-8ffd-3807c64a4b52"}
{"timestamp": "2024-08-27T12:37:11.921240+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data validation error occurred\", \"error_message\": \"Invalid first_start_date format\", \"error_type\": \"DataValidationError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 100, in scrape_and_save_all_boxscores\\n    raise DataValidationError(\\\"Invalid first_start_date format\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Invalid first_start_date format\\n\"}", "error_id": "f80ef0a9-5fd9-4b54-841d-02824b6443b4"}
{"timestamp": "2024-08-27T12:42:55.418414+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 114, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 276, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 122, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "3984304d-be37-4c8d-b00a-adb8848616de"}
{"timestamp": "2024-08-27T12:50:08.199795+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 114, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 276, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 122, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "084c9709-636f-478b-b09a-59cb736e4ac3"}
{"timestamp": "2024-08-27T12:55:56.854879+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "5ee07776-d119-4411-9f9a-e74c343e05f6"}
{"timestamp": "2024-08-27T12:57:27.656757+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "df05736a-4408-4c46-a513-854bb387bea6"}
{"timestamp": "2024-08-27T12:58:02.209731+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "e22800f8-36fe-47e9-9a02-4d026f27da6f"}
{"timestamp": "2024-08-27T12:59:17.118627+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "8fc3e330-e777-497b-ada3-86bc8c01dfd0"}
{"timestamp": "2024-08-27T13:01:46.990005+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "57b51209-dc89-4b00-abb8-5b4cdc6ee848"}
{"timestamp": "2024-08-27T13:09:20.509634+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "6d75ca85-4027-4786-bd8c-a56bef8b84ce"}
{"timestamp": "2024-08-27T13:10:19.624827+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "f67d6b5a-3cb9-409f-8695-0b3f17f226f7"}
{"timestamp": "2024-08-27T13:47:20.680031+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "2aad2c41-952f-46a1-bf13-c7c50b1e3650"}
{"timestamp": "2024-08-27T13:47:58.155475+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "0ea16c79-b750-43cd-9815-a0cc77dab059"}
{"timestamp": "2024-08-28T12:44:26.106630+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 75, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 237, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 83, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "3eac759d-40a4-4e29-8a6b-ec86a8c60b48"}
{"timestamp": "2024-08-28T12:50:15.675374+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 75, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 237, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 83, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "41c5674c-cbd9-4214-b733-a11abb339f52"}
{"timestamp": "2024-08-28T12:57:19.765559+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 75, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 237, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 83, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "63064ac8-c6b3-4ee9-966b-991e889a0493"}
{"timestamp": "2024-08-29T13:42:14.960175+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 78, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 240, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 86, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "28e729b0-a126-4c25-b05e-6b2343172d46"}
{"timestamp": "2024-08-29T13:48:58.904575+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 158, in handle_pagination\\n    self.wait.until(EC.staleness_of(pagination))\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 250, in scrape_page_table\\n    self.handle_pagination(pagination_class, dropdown_class)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 167, in handle_pagination\\n    raise ElementNotFoundError(\\\"No pagination found on the page\\\",\\nsrc.error_handling.custom_exceptions.ElementNotFoundError: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 289, in scrape_boxscores_table\\n    raise ScrapingError(f\\\"Error scraping table: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\"}", "error_id": "98de2b70-5e68-41dc-aa19-700be51e926c"}
{"timestamp": "2024-08-29T13:54:46.283994+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 158, in handle_pagination\\n    self.wait.until(EC.staleness_of(pagination))\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 250, in scrape_page_table\\n    self.handle_pagination(pagination_class, dropdown_class)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 167, in handle_pagination\\n    raise ElementNotFoundError(\\\"No pagination found on the page\\\",\\nsrc.error_handling.custom_exceptions.ElementNotFoundError: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 289, in scrape_boxscores_table\\n    raise ScrapingError(f\\\"Error scraping table: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\"}", "error_id": "6a4b88c1-8328-4596-81f4-3ce4d79a7d74"}
{"timestamp": "2024-08-31T15:25:13.032869+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 370, in _extract_team_and_game_ids_boxscores\\n    links = self.page_scraper.get_elements_by_class(self.config.teams_and_games_class_name, data_table)\\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 308, in _convert_table_to_df\\n    team_id, game_id = self._extract_team_and_game_ids_boxscores(data_table)\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 382, in _extract_team_and_game_ids_boxscores\\n    raise DataExtractionError(f\\\"Error extracting team and game IDs: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataExtractionError: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 136, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 173, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 250, in scrape_to_dataframe\\n    df = self._convert_table_to_df(data_table)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 318, in _convert_table_to_df\\n    raise DataExtractionError(f\\\"Error converting table to DataFrame: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataExtractionError: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 103, in scrape_and_save_all_boxscores\\n    self._boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 98, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 146, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 93, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 115, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\"}", "error_id": "07bd80dc-3213-436d-950c-a4a68f648ae3"}

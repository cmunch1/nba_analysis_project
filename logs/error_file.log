{"timestamp": 1724595674.1630023, "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "e3cf6e2b-9160-4159-a5f3-14ea88bd98bf"}
{"timestamp": 1724598334.1091247, "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "6d8559fc-c45f-4ffa-9e13-c8a6e9cf8733"}
{"timestamp": 1724598788.9599376, "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"timestamp\": \"2024-08-25T10:13:08.959937\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "ca1b2f45-bd4d-4347-9d23-66abb02a5ef2"}
{"timestamp": "2024-08-25T15:21:42.422646+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data processing error occurred\", \"error_message\": \"Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 53, in get_start_date_and_seasons\\n    first_start_date, seasons = determine_scrape_start(scraped_data, config)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 89, in determine_scrape_start\\n    raise DataValidationError(f\\\"Dataframe {i} does not have a recognized game date column\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 does not have a recognized game date column\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 82, in main\\n    first_start_date, seasons = get_start_date_and_seasons(config, data_access)\\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\utils.py\\\", line 65, in get_start_date_and_seasons\\n    raise DataProcessingError(f\\\"Error in get_start_date_and_seasons: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in get_start_date_and_seasons: Dataframe 1 does not have a recognized game date column\\n\"}", "error_id": "8abd7d4a-8ed6-4eaa-81a6-29dd7eb9b0df"}
{"timestamp": "2024-08-25T15:59:58.871147+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 136, in handle_pagination\\n    pagination = self.wait.until(EC.presence_of_element_located((By.CLASS_NAME, pagination_class)))\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\nStacktrace:\\n\\tGetHandleVerifier [0x00228923+23283]\\n\\t(No symbol) [0x001EE934]\\n\\t(No symbol) [0x00120733]\\n\\t(No symbol) [0x0016326F]\\n\\t(No symbol) [0x001634AB]\\n\\t(No symbol) [0x0019EE42]\\n\\t(No symbol) [0x00184464]\\n\\t(No symbol) [0x0019CB8D]\\n\\t(No symbol) [0x001841B6]\\n\\t(No symbol) [0x00158017]\\n\\t(No symbol) [0x0015890D]\\n\\tGetHandleVerifier [0x0031A5F3+1013699]\\n\\tGetHandleVerifier [0x00323E4C+1052700]\\n\\tGetHandleVerifier [0x0031D4B4+1025668]\\n\\tGetHandleVerifier [0x0024EA2B+179195]\\n\\t(No symbol) [0x001F6833]\\n\\t(No symbol) [0x001F3198]\\n\\t(No symbol) [0x001F3337]\\n\\t(No symbol) [0x001EB4BE]\\n\\tBaseThreadInitThunk [0x7527FCC9+25]\\n\\tRtlGetAppContainerNamedObjectPath [0x76F280CE+286]\\n\\tRtlGetAppContainerNamedObjectPath [0x76F2809E+238]\\n\\t(No symbol) [0x00000000]\\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 222, in scrape_page_table\\n    self.handle_pagination(pagination_class, dropdown_class)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 154, in handle_pagination\\n    raise ElementNotFoundError(\\\"No pagination found on the page\\\")\\nsrc.error_handling.custom_exceptions.ElementNotFoundError: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 289, in scrape_boxscores_table\\n    raise ScrapingError(f\\\"Error scraping table: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\"}", "error_id": "10b70635-0d10-4d07-a3fe-08547a0e7849"}
{"timestamp": "2024-08-25T17:23:18.071518+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 112, in go_to_url\\n    self.web_driver.set_page_load_timeout(self.config.page_load_timeout)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 267, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 136, in go_to_url\\n    raise PageLoadError(f\\\"Error navigating to {url}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\"}", "error_id": "cc962a7e-f883-42c8-939d-2e4c647f422e"}
{"timestamp": "2024-08-25T17:26:57.303641+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 112, in go_to_url\\n    self.web_driver.set_page_load_timeout(self.config.page_load_timeout)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 267, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 136, in go_to_url\\n    raise PageLoadError(f\\\"Error navigating to {url}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error navigating to https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024: 'Config' object has no attribute 'page_load_timeout'\\n\"}", "error_id": "7d045a54-45ac-49f3-b59b-f10c7edc4e8f"}
{"timestamp": "2024-08-25T17:29:46.265221+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 269, in scrape_page_table\\n    raise PageLoadError(f\\\"Could not navigate to URL: {url}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\"}", "error_id": "a62d375a-3345-4fb0-a965-6eb9024cb730"}
{"timestamp": "2024-08-25T18:05:49.697041+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 287, in scrape_page_table\\n    raise PageLoadError(f\\\"Could not navigate to URL: {url}\\\")\\nsrc.error_handling.custom_exceptions.PageLoadError: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Could not navigate to URL: https://www.nba.com/stats/teams/boxscores?SeasonType=Playoffs&Season=2023-24&DateFrom=05/11/2024&DateTo=8/01/2024\\n\"}", "error_id": "e6959f32-9aad-47b1-bddb-97ec64d26168"}
{"timestamp": "2024-08-25T18:46:56.073637+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 117, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 279, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 125, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "824619c1-6535-4f6e-bd3b-65dd330f711b"}
{"timestamp": "2024-08-26T12:44:06.026752+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "23e694cf-78a9-4a00-9677-0a21c20f47ff"}
{"timestamp": "2024-08-27T12:09:02.236253+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "045d2716-5331-450f-8ffd-3807c64a4b52"}
{"timestamp": "2024-08-27T12:37:11.921240+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Data validation error occurred\", \"error_message\": \"Invalid first_start_date format\", \"error_type\": \"DataValidationError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 100, in scrape_and_save_all_boxscores\\n    raise DataValidationError(\\\"Invalid first_start_date format\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Invalid first_start_date format\\n\"}", "error_id": "f80ef0a9-5fd9-4b54-841d-02824b6443b4"}
{"timestamp": "2024-08-27T12:42:55.418414+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 114, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 276, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 122, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "3984304d-be37-4c8d-b00a-adb8848616de"}
{"timestamp": "2024-08-27T12:50:08.199795+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 114, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 276, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 122, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "084c9709-636f-478b-b09a-59cb736e4ac3"}
{"timestamp": "2024-08-27T12:55:56.854879+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "5ee07776-d119-4411-9f9a-e74c343e05f6"}
{"timestamp": "2024-08-27T12:57:27.656757+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "df05736a-4408-4c46-a513-854bb387bea6"}
{"timestamp": "2024-08-27T12:58:02.209731+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "e22800f8-36fe-47e9-9a02-4d026f27da6f"}
{"timestamp": "2024-08-27T12:59:17.118627+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "8fc3e330-e777-497b-ada3-86bc8c01dfd0"}
{"timestamp": "2024-08-27T13:01:46.990005+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "57b51209-dc89-4b00-abb8-5b4cdc6ee848"}
{"timestamp": "2024-08-27T13:09:20.509634+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "6d75ca85-4027-4786-bd8c-a56bef8b84ce"}
{"timestamp": "2024-08-27T13:10:19.624827+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "f67d6b5a-3cb9-409f-8695-0b3f17f226f7"}
{"timestamp": "2024-08-27T13:47:20.680031+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "2aad2c41-952f-46a1-bf13-c7c50b1e3650"}
{"timestamp": "2024-08-27T13:47:58.155475+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 113, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 275, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 121, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "0ea16c79-b750-43cd-9815-a0cc77dab059"}
{"timestamp": "2024-08-28T12:44:26.106630+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 75, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 237, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 83, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "3eac759d-40a4-4e29-8a6b-ec86a8c60b48"}
{"timestamp": "2024-08-28T12:50:15.675374+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 75, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 237, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 83, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "41c5674c-cbd9-4214-b733-a11abb339f52"}
{"timestamp": "2024-08-28T12:57:19.765559+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 75, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 237, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 83, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "63064ac8-c6b3-4ee9-966b-991e889a0493"}
{"timestamp": "2024-08-29T13:42:14.960175+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 78, in go_to_url\\n    WebDriverWait(self.web_driver, self.config.wait_time).until(\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 240, in scrape_page_table\\n    success = self.go_to_url(url)\\n              ^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 86, in go_to_url\\n    raise PageLoadError(\\\"Timeout occurred while loading URL\\\", url=url, timeout=self.config.page_load_timeout)\\nsrc.error_handling.custom_exceptions.PageLoadError: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Timeout occurred while loading URL\\n\"}", "error_id": "28e729b0-a126-4c25-b05e-6b2343172d46"}
{"timestamp": "2024-08-29T13:48:58.904575+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 158, in handle_pagination\\n    self.wait.until(EC.staleness_of(pagination))\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 250, in scrape_page_table\\n    self.handle_pagination(pagination_class, dropdown_class)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 167, in handle_pagination\\n    raise ElementNotFoundError(\\\"No pagination found on the page\\\",\\nsrc.error_handling.custom_exceptions.ElementNotFoundError: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 289, in scrape_boxscores_table\\n    raise ScrapingError(f\\\"Error scraping table: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\"}", "error_id": "98de2b70-5e68-41dc-aa19-700be51e926c"}
{"timestamp": "2024-08-29T13:54:46.283994+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 158, in handle_pagination\\n    self.wait.until(EC.staleness_of(pagination))\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\selenium\\\\webdriver\\\\support\\\\wait.py\\\", line 105, in until\\n    raise TimeoutException(message, screen, stacktrace)\\nselenium.common.exceptions.TimeoutException: Message: \\n\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 283, in scrape_boxscores_table\\n    table = self.page_scraper.scrape_page_table(nba_url, self.config.table_class_name, self.config.pagination_class_name, self.config.dropdown_class_name)\\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 250, in scrape_page_table\\n    self.handle_pagination(pagination_class, dropdown_class)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\page_scraper.py\\\", line 167, in handle_pagination\\n    raise ElementNotFoundError(\\\"No pagination found on the page\\\",\\nsrc.error_handling.custom_exceptions.ElementNotFoundError: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 137, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 174, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 244, in scrape_to_dataframe\\n    data_table = self.scrape_boxscores_table(Season, DateFrom, DateTo, stat_type, season_type)\\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 289, in scrape_boxscores_table\\n    raise ScrapingError(f\\\"Error scraping table: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 107, in scrape_and_save_all_boxscores\\n    self.boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 99, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 147, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 91, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 129, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error scraping table: No pagination found on the page\\n\"}", "error_id": "6a4b88c1-8328-4596-81f4-3ce4d79a7d74"}
{"timestamp": "2024-08-31T15:25:13.032869+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"Scraping error occurred\", \"error_message\": \"Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\", \"error_type\": \"ScrapingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 370, in _extract_team_and_game_ids_boxscores\\n    links = self.page_scraper.get_elements_by_class(self.config.teams_and_games_class_name, data_table)\\n     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 308, in _convert_table_to_df\\n    team_id, game_id = self._extract_team_and_game_ids_boxscores(data_table)\\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 382, in _extract_team_and_game_ids_boxscores\\n    raise DataExtractionError(f\\\"Error extracting team and game IDs: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataExtractionError: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 136, in scrape_stat_type\\n    df_season = self.scrape_sub_seasons(str(season), str(start_date), str(end_date), stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 173, in scrape_sub_seasons\\n    df = self.scrape_to_dataframe(Season=season, DateFrom=start_date, DateTo=end_date, stat_type=stat_type, season_type=sub_season_type)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 250, in scrape_to_dataframe\\n    df = self._convert_table_to_df(data_table)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 318, in _convert_table_to_df\\n    raise DataExtractionError(f\\\"Error converting table to DataFrame: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataExtractionError: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 103, in scrape_and_save_all_boxscores\\n    self._boxscore_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 98, in scrape_and_save_all_boxscores\\n    new_games = self.scrape_stat_type(seasons, first_start_date, stat_type)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\boxscore_scraper.py\\\", line 146, in scrape_stat_type\\n    raise DataProcessingError(f\\\"Error processing scraped data for {stat_type}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error processing scraped data for traditional: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\test_main.py\\\", line 93, in main\\n    nba_scraper.scrape_and_save_all_boxscores(seasons, first_start_date)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\webscraping\\\\nba_scraper.py\\\", line 115, in scrape_and_save_all_boxscores\\n    raise ScrapingError(f\\\"Unexpected error occurred while scraping boxscores: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.ScrapingError: Unexpected error occurred while scraping boxscores: Error processing scraped data for traditional: Error converting table to DataFrame: Error extracting team and game IDs: 'PageScraper' object has no attribute 'get_elements_by_class'\\n\"}", "error_id": "07bd80dc-3213-436d-950c-a4a68f648ae3"}
{"timestamp": "2024-09-08T20:39:54.940614+00:00", "level": "CRITICAL", "name": "error_logger", "message": "{\"message\": \"Unexpected error occurred\", \"error_message\": \"'DataAccess' object has no attribute 'load_dataframes'\", \"error_type\": \"AttributeError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 45, in main\\n    scraped_dataframes, file_names = data_access.load_dataframes(cumulative=True)\\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataAccess' object has no attribute 'load_dataframes'\\n\"}", "error_id": "c82159bd-2bc4-4493-89bb-92651b791514"}
{"timestamp": "2024-09-09T12:39:34.928412+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataValidationError occurred\", \"error_message\": \"Dataframe 1 has inconsistent columns\", \"error_type\": \"DataValidationError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 45, in main\\n    scraped_dataframes, file_names = data_access.load_scraped_data(cumulative=True)\\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 100, in load_scraped_data\\n    self._validate_loaded_data(all_dfs)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 205, in _validate_loaded_data\\n    raise DataValidationError(f\\\"Dataframe {i} has inconsistent columns\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 has inconsistent columns\\n\"}", "error_id": "939d82bc-84d9-4998-b585-8ef9a27a0347"}
{"timestamp": "2024-09-09T12:43:32.469735+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataValidationError occurred\", \"error_message\": \"Dataframe 1 has inconsistent columns\", \"error_type\": \"DataValidationError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 45, in main\\n    scraped_dataframes, file_names = data_access.load_scraped_data(cumulative=True)\\n                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 100, in load_scraped_data\\n    self._validate_loaded_data(all_dfs)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 205, in _validate_loaded_data\\n    raise DataValidationError(f\\\"Dataframe {i} has inconsistent columns\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe 1 has inconsistent columns\\n\"}", "error_id": "785506c1-ed22-4839-88ae-caab1cc27b15"}
{"timestamp": "2024-09-10T12:13:45.311999+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Unexpected error in process_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 45, in process_data\\n    df = self._handle_anomalous_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 117, in _handle_anomalous_data\\n    structured_log(logger, logging.INFO, \\\"Starting handle_anomalous_data\\\",\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 61, in structured_log\\n    logger.log(level, json.dumps(log_data))\\n                      ^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\json\\\\__init__.py\\\", line 231, in dumps\\n    return _default_encoder.encode(obj)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\json\\\\encoder.py\\\", line 200, in encode\\n    chunks = self.iterencode(o, _one_shot=True)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\json\\\\encoder.py\\\", line 258, in iterencode\\n    return _iterencode(o, 0)\\n           ^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\json\\\\encoder.py\\\", line 180, in default\\n    raise TypeError(f'Object of type {o.__class__.__name__} '\\nTypeError: Object of type int64 is not JSON serializable\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 61, in process_data\\n    raise DataProcessingError(\\\"Unexpected error in process_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Unexpected error in process_data\\n\"}", "error_id": "565438a1-510e-4b2f-ba63-da1ab13a37ab"}
{"timestamp": "2024-09-10T12:22:20.514820+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3805, in get_loc\\n    return self._engine.get_loc(casted_key)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"index.pyx\\\", line 167, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 191, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 234, in pandas._libs.index.IndexEngine._get_loc_duplicates\\n  File \\\"index.pyx\\\", line 242, in pandas._libs.index.IndexEngine._maybe_get_bool_indexer\\n  File \\\"index.pyx\\\", line 134, in pandas._libs.index._unpack_bool_indexer\\nKeyError: 'W/L'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 221, in _extract_new_columns\\n    df[\\\"is_win\\\"] = df[\\\"W/L\\\"].str.contains(\\\"W\\\").astype(int)\\n                   ~~^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4102, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3812, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'W/L'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 236, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "c4e8f2c8-6e13-457b-bda7-a7da1a574216"}
{"timestamp": "2024-09-10T12:32:51.452730+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3805, in get_loc\\n    return self._engine.get_loc(casted_key)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"index.pyx\\\", line 167, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 191, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 234, in pandas._libs.index.IndexEngine._get_loc_duplicates\\n  File \\\"index.pyx\\\", line 242, in pandas._libs.index.IndexEngine._maybe_get_bool_indexer\\n  File \\\"index.pyx\\\", line 134, in pandas._libs.index._unpack_bool_indexer\\nKeyError: 'W/L'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 223, in _extract_new_columns\\n    df[\\\"is_win\\\"] = df[\\\"W/L\\\"].str.contains(\\\"W\\\").astype(int)\\n                   ~~^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4102, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3812, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'W/L'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 161, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 238, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 48, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 168, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "70c481c4-ad31-46b5-81ac-c30b4e469ca3"}
{"timestamp": "2024-09-10T12:34:08.197447+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3805, in get_loc\\n    return self._engine.get_loc(casted_key)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"index.pyx\\\", line 167, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 191, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 234, in pandas._libs.index.IndexEngine._get_loc_duplicates\\n  File \\\"index.pyx\\\", line 242, in pandas._libs.index.IndexEngine._maybe_get_bool_indexer\\n  File \\\"index.pyx\\\", line 134, in pandas._libs.index._unpack_bool_indexer\\nKeyError: 'W/L'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 222, in _extract_new_columns\\n    df[\\\"is_win\\\"] = df[\\\"W/L\\\"].str.contains(\\\"W\\\").astype(int)\\n                   ~~^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4102, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3812, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'W/L'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 160, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 237, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 47, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 167, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "6519fde5-adb1-4aac-ac5c-dfd585b28ea0"}
{"timestamp": "2024-09-10T12:35:15.929401+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3805, in get_loc\\n    return self._engine.get_loc(casted_key)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"index.pyx\\\", line 167, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 191, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 234, in pandas._libs.index.IndexEngine._get_loc_duplicates\\n  File \\\"index.pyx\\\", line 242, in pandas._libs.index.IndexEngine._maybe_get_bool_indexer\\n  File \\\"index.pyx\\\", line 134, in pandas._libs.index._unpack_bool_indexer\\nKeyError: 'W/L'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 222, in _extract_new_columns\\n    df[\\\"is_win\\\"] = df[\\\"W/L\\\"].str.contains(\\\"W\\\").astype(int)\\n                   ~~^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4102, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3812, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'W/L'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 160, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 237, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 167, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "e7f74bb6-6ce2-47f4-ba22-cc3de76b84ec"}
{"timestamp": "2024-09-10T12:41:17.797366+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 226, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 238, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "1aa79bff-1dd5-43e6-b965-572f57bc733d"}
{"timestamp": "2024-09-10T12:47:39.090817+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 226, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 238, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "72311fa4-0e33-497a-aadc-a1307e31c649"}
{"timestamp": "2024-09-10T12:50:18.768128+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 268, in _reorder_columns\\n    reordered_df = df[game_info + team_info + team_stats]\\n                   ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4108, in __getitem__\\n    indexer = self.columns._get_indexer_strict(key, \\\"columns\\\")[1]\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 6200, in _get_indexer_strict\\n    self._raise_if_missing(keyarr, indexer, axis_name)\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 6252, in _raise_if_missing\\n    raise KeyError(f\\\"{not_found} not in index\\\")\\nKeyError: \\\"['GAME_ID', 'SEASON', 'Game Date', 'PLAYOFF', 'OVERTIME', 'MIN', 'TEAM_ID', 'HOME_TEAM', 'Team', 'Match Up'] not in index\\\"\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 160, in _transform_data\\n    df = self._reorder_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 273, in _reorder_columns\\n    raise DataProcessingError(\\\"Error in reorder_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in reorder_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "bf1ccfcf-0521-487d-ae9d-7f6614274d29"}
{"timestamp": "2024-09-10T12:53:34.304478+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 268, in _reorder_columns\\n    reordered_df = df[game_info + team_info + team_stats]\\n                   ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4108, in __getitem__\\n    indexer = self.columns._get_indexer_strict(key, \\\"columns\\\")[1]\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 6200, in _get_indexer_strict\\n    self._raise_if_missing(keyarr, indexer, axis_name)\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 6252, in _raise_if_missing\\n    raise KeyError(f\\\"{not_found} not in index\\\")\\nKeyError: \\\"['playoff', 'overtime', 'home_team'] not in index\\\"\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 160, in _transform_data\\n    df = self._reorder_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 273, in _reorder_columns\\n    raise DataProcessingError(\\\"Error in reorder_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in reorder_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "1a8af542-af62-4b5b-94c3-87cc51fbc49b"}
{"timestamp": "2024-09-10T12:56:25.189015+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 226, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 238, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "4d0fb06b-5299-46dc-808d-176beb005cee"}
{"timestamp": "2024-09-10T13:01:34.875440+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 229, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 241, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "8abc3ba5-a0df-40b8-89eb-1855022697a3"}
{"timestamp": "2024-09-11T12:43:18.057854+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 231, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 243, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "5b76d2fc-db16-4544-b3b5-efbf6c192a2f"}
{"timestamp": "2024-09-11T12:44:29.275684+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 231, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\")\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 243, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "0ae0bd8f-5d37-47f8-a9d9-d8e425788d86"}
{"timestamp": "2024-09-11T12:48:06.041034+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 232, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 159, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 244, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 166, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "1c3f5e87-79ee-49c1-883b-95c26d9904c7"}
{"timestamp": "2024-09-11T12:52:55.817041+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 232, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 160, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 244, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 167, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "8567de9a-faf1-44c5-82be-48db407e9386"}
{"timestamp": "2024-09-11T12:58:30.092768+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 233, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 161, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 245, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 168, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "c3f31392-5334-4558-b21d-2d9d6b5d7ad8"}
{"timestamp": "2024-09-11T13:35:41.943691+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 233, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 161, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 245, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 168, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "660c6780-c9ae-4b39-b8d9-3488f6b6f874"}
{"timestamp": "2024-09-11T13:38:30.325318+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 234, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 162, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 246, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 169, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "fdfb99e6-269f-4f11-a66e-a2ca48c6d772"}
{"timestamp": "2024-09-11T13:45:55.241402+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 233, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 161, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 245, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 168, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "21f1bd1f-9c78-4d0d-b20e-a976c1dd6fde"}
{"timestamp": "2024-09-11T13:51:39.125653+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 233, in _extract_new_columns\\n    df[\\\"is_home_team\\\"] = df[\\\"match_up\\\"].str.contains(\\\"vs.\\\").astype(int)\\n                         ^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'DataFrame' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 161, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 245, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df = self._transform_data(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 168, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "7cee0fdd-bcfb-4d8b-a2d0-ee3ca5f9bc16"}
{"timestamp": "2024-09-11T13:56:31.332107+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in validate_scraped_dataframes: 'GAME_ID'\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_validation\\\\data_validator.py\\\", line 50, in validate_scraped_dataframes\\n    df = df.sort_values(by=self.config.game_id_column)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 7189, in sort_values\\n    k = self._get_label_or_level_values(by[0], axis=axis)\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 1911, in _get_label_or_level_values\\n    raise KeyError(key)\\nKeyError: 'GAME_ID'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 55, in main\\n    if not data_validator.validate_scraped_dataframes(processed_dataframes, processed_file_names):\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_validation\\\\data_validator.py\\\", line 70, in validate_scraped_dataframes\\n    raise DataProcessingError(f\\\"Error in validate_scraped_dataframes: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in validate_scraped_dataframes: 'GAME_ID'\\n\"}", "error_id": "b85302db-668d-432d-9131-3321b83bd605"}
{"timestamp": "2024-09-12T13:49:10.784296+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in validate_scraped_dataframes: 'game_id'\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_validation\\\\data_validator.py\\\", line 51, in validate_scraped_dataframes\\n    df = df.sort_values(by=game_id_column)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 7189, in sort_values\\n    k = self._get_label_or_level_values(by[0], axis=axis)\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 1911, in _get_label_or_level_values\\n    raise KeyError(key)\\nKeyError: 'game_id'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 47, in main\\n    if not data_validator.validate_scraped_dataframes(scraped_dataframes, file_names):\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_validation\\\\data_validator.py\\\", line 71, in validate_scraped_dataframes\\n    raise DataProcessingError(f\\\"Error in validate_scraped_dataframes: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in validate_scraped_dataframes: 'game_id'\\n\"}", "error_id": "3850933b-159b-4b91-bd6b-ac05ec147b8c"}
{"timestamp": "2024-09-14T13:35:59.819704+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataValidationError occurred\", \"error_message\": \"Dataframe ['cleaned_and_combined_data.csv'] failed schema validation\", \"error_type\": \"DataValidationError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 53, in main\\n    if not data_validator.validate_processed_dataframe(processed_dataframe, processed_file_name):\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_validation\\\\data_validator.py\\\", line 91, in validate_processed_dataframe\\n    raise DataValidationError(f\\\"Dataframe {file_name} failed schema validation\\\")\\nsrc.error_handling.custom_exceptions.DataValidationError: Dataframe ['cleaned_and_combined_data.csv'] failed schema validation\\n\"}", "error_id": "f224ab91-34de-468b-b49c-833413604795"}
{"timestamp": "2024-09-14T13:37:31.512729+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataStorageError occurred\", \"error_message\": \"Error saving dataframes: Error saving data to ['cleaned_and_combined_data.csv']: unsupported operand type(s) for /: 'WindowsPath' and 'list'\", \"error_type\": \"DataStorageError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 59, in _save_dataframe_csv\\n    df.to_csv(file_path / file_name, index=False)\\n              ~~~~~~~~~~^~~~~~~~~~~\\nTypeError: unsupported operand type(s) for /: 'WindowsPath' and 'list'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 77, in save_dataframes\\n    self._save_dataframe_csv(df, file_name, cumulative=cumulative)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 63, in _save_dataframe_csv\\n    raise DataStorageError(f\\\"Error saving data to {file_name}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataStorageError: Error saving data to ['cleaned_and_combined_data.csv']: unsupported operand type(s) for /: 'WindowsPath' and 'list'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 56, in main\\n    data_access.save_dataframes([processed_dataframe], [processed_file_name], cumulative=True) # expects a list of dataframes and a list of file names\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 80, in save_dataframes\\n    raise DataStorageError(f\\\"Error saving dataframes: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataStorageError: Error saving dataframes: Error saving data to ['cleaned_and_combined_data.csv']: unsupported operand type(s) for /: 'WindowsPath' and 'list'\\n\"}", "error_id": "acd805cb-62ec-446f-bda2-a7672fa46892"}
{"timestamp": "2024-09-14T16:13:54.525385+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataStorageError occurred\", \"error_message\": \"Error saving column mapping: DataAccess._get_save_directory() missing 1 required positional argument: 'file_name'\", \"error_type\": \"DataStorageError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 127, in save_column_mapping\\n    file_path = self._get_save_directory(cumulative=True)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\nTypeError: DataAccess._get_save_directory() missing 1 required positional argument: 'file_name'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 57, in main\\n    data_access.save_column_mapping(column_mapping, config.column_mapping_file)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 134, in save_column_mapping\\n    raise DataStorageError(f\\\"Error saving column mapping: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataStorageError: Error saving column mapping: DataAccess._get_save_directory() missing 1 required positional argument: 'file_name'\\n\"}", "error_id": "dc5b1647-1a63-4904-aedf-caa3ca35e7ae"}
{"timestamp": "2024-09-14T16:18:00.748395+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Unexpected error in process_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 48, in process_data\\n    df = df.sort_values(by=self.config.game_id_column, ascending=True)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 7189, in sort_values\\n    k = self._get_label_or_level_values(by[0], axis=axis)\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 1911, in _get_label_or_level_values\\n    raise KeyError(key)\\nKeyError: 'GAME_ID'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe, column_mapping = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 63, in process_data\\n    raise DataProcessingError(\\\"Unexpected error in process_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Unexpected error in process_data\\n\"}", "error_id": "e0924796-22b8-403c-be67-268a2219de34"}
{"timestamp": "2024-09-14T16:20:03.606136+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Unexpected error in process_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3805, in get_loc\\n    return self._engine.get_loc(casted_key)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"index.pyx\\\", line 167, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"index.pyx\\\", line 196, in pandas._libs.index.IndexEngine.get_loc\\n  File \\\"pandas\\\\\\\\_libs\\\\\\\\hashtable_class_helper.pxi\\\", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item\\n  File \\\"pandas\\\\\\\\_libs\\\\\\\\hashtable_class_helper.pxi\\\", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item\\nKeyError: 'GAME_ID'\\n\\nThe above exception was the direct cause of the following exception:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 48, in process_data\\n    new_game_id_column = df[self.config.game_id_column].astype(str).str.lower()\\n                         ~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\frame.py\\\", line 4102, in __getitem__\\n    indexer = self.columns.get_loc(key)\\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\indexes\\\\base.py\\\", line 3812, in get_loc\\n    raise KeyError(key) from err\\nKeyError: 'GAME_ID'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe, column_mapping = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 64, in process_data\\n    raise DataProcessingError(\\\"Unexpected error in process_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Unexpected error in process_data\\n\"}", "error_id": "6f94dc55-81d4-45c8-9c02-8930e1aa1a8a"}
{"timestamp": "2024-09-14T16:20:53.648594+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Unexpected error in process_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 48, in process_data\\n    new_game_id_column = self.config.game_id_column.str.lower()\\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'str' object has no attribute 'str'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe, column_mapping = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 64, in process_data\\n    raise DataProcessingError(\\\"Unexpected error in process_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Unexpected error in process_data\\n\"}", "error_id": "71b20144-3c84-4391-bdb7-b2fe9b0af8a0"}
{"timestamp": "2024-09-14T16:32:58.287398+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 246, in _extract_new_columns\\n    df[\\\"sub_season_id\\\"] = df[\\\"game_id\\\"].str[:1].astype(int)\\n                          ^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\generic.py\\\", line 6299, in __getattr__\\n    return object.__getattribute__(self, name)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\accessor.py\\\", line 224, in __get__\\n    accessor_obj = self._accessor(obj)\\n                   ^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\strings\\\\accessor.py\\\", line 191, in __init__\\n    self._inferred_dtype = self._validate(data)\\n                           ^^^^^^^^^^^^^^^^^^^^\\n  File \\\"C:\\\\Users\\\\Chris\\\\miniconda3\\\\envs\\\\nba_analysis\\\\Lib\\\\site-packages\\\\pandas\\\\core\\\\strings\\\\accessor.py\\\", line 245, in _validate\\n    raise AttributeError(\\\"Can only use .str accessor with string values!\\\")\\nAttributeError: Can only use .str accessor with string values!\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 162, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 256, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe, column_mapping = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df, column_mapping = self._transform_data(df)\\n                         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 170, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "a5040afe-0e15-4fa7-a9b7-95b76688080a"}
{"timestamp": "2024-09-14T16:46:11.294465+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataProcessingError occurred\", \"error_message\": \"Error in transform_data\", \"error_type\": \"DataProcessingError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 242, in _extract_new_columns\\n    df[self.config.new.game_id_column] = df[self.config.new.game_id_column].astype(str)\\n                                            ^^^^^^^^^^^^^^^\\nAttributeError: 'Config' object has no attribute 'new'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 161, in _transform_data\\n    df = self._extract_new_columns(df)\\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 255, in _extract_new_columns\\n    raise DataProcessingError(\\\"Error in extract_new_columns\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in extract_new_columns\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 50, in main\\n    processed_dataframe, column_mapping = process_scraped_NBA_data.process_data(scraped_dataframes)\\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 46, in process_data\\n    df, column_mapping = self._transform_data(df)\\n                         ^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\process_scraped_NBA_data.py\\\", line 169, in _transform_data\\n    raise DataProcessingError(\\\"Error in transform_data\\\",\\nsrc.error_handling.custom_exceptions.DataProcessingError: Error in transform_data\\n\"}", "error_id": "d94a0b94-cf37-42c7-b329-ac346bd626de"}
{"timestamp": "2024-09-14T18:40:46.785790+00:00", "level": "ERROR", "name": "error_logger", "message": "{\"message\": \"DataStorageError occurred\", \"error_message\": \"Error saving dataframes: Error saving data to teams_boxscores.csv: 'Config' object has no attribute 'cleaned_and_combined_data_file'\", \"error_type\": \"DataStorageError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 58, in _save_dataframe_csv\\n    file_path = self._get_save_directory(cumulative, file_name)\\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 154, in _get_save_directory\\n    if file_name == self.config.cleaned_and_combined_data_file:\\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'Config' object has no attribute 'cleaned_and_combined_data_file'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 78, in save_dataframes\\n    self._save_dataframe_csv(df, file_name, cumulative=cumulative)\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 64, in _save_dataframe_csv\\n    raise DataStorageError(f\\\"Error saving data to {file_name}: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataStorageError: Error saving data to teams_boxscores.csv: 'Config' object has no attribute 'cleaned_and_combined_data_file'\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 56, in main\\n    data_access.save_dataframes([processed_dataframe], [processed_file_name], cumulative=True) # expects a list of dataframes and a list of file names\\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\logging\\\\logging_utils.py\\\", line 15, in wrapper\\n    result = func(*args, **kwargs)\\n             ^^^^^^^^^^^^^^^^^^^^^\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_access\\\\data_access.py\\\", line 81, in save_dataframes\\n    raise DataStorageError(f\\\"Error saving dataframes: {str(e)}\\\")\\nsrc.error_handling.custom_exceptions.DataStorageError: Error saving dataframes: Error saving data to teams_boxscores.csv: 'Config' object has no attribute 'cleaned_and_combined_data_file'\\n\"}", "error_id": "eedf419f-5c18-4136-b7ad-a5cbe2be3126"}
{"timestamp": "2024-09-14T18:42:22.671393+00:00", "level": "CRITICAL", "name": "error_logger", "message": "{\"message\": \"Unexpected error occurred\", \"error_message\": \"'ProcessScrapedNBAData' object has no attribute 'combine_team_data'\", \"error_type\": \"AttributeError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 60, in main\\n    processed_dataframe = process_scraped_NBA_data.combine_team_data(processed_dataframe)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'ProcessScrapedNBAData' object has no attribute 'combine_team_data'\\n\"}", "error_id": "df4eb023-eaae-4498-81c0-02e057bd3eef"}
{"timestamp": "2024-09-14T18:51:14.229645+00:00", "level": "CRITICAL", "name": "error_logger", "message": "{\"message\": \"Unexpected error occurred\", \"error_message\": \"'ProcessScrapedNBAData' object has no attribute 'merge_team_data_team_data'\", \"error_type\": \"AttributeError\", \"traceback\": \"Traceback (most recent call last):\\n  File \\\"E:\\\\OneDrive\\\\nba_analysis_project\\\\src\\\\data_processing\\\\main.py\\\", line 60, in main\\n    processed_dataframe = process_scraped_NBA_data.merge_team_data_team_data(processed_dataframe)\\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: 'ProcessScrapedNBAData' object has no attribute 'merge_team_data_team_data'\\n\"}", "error_id": "fab80549-a323-4247-a1a0-73eb9bf2c5c1"}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_scraped_data' from 'src.data_access' (e:\\OneDrive\\nba_analysis_project\\src\\data_access\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#%config InlineBackend.figure_format = 'svg'\u001b[39;00m\n\u001b[0;32m     12\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#change to parent directory\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_access\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     load_scraped_data,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     merge_scraped_dataframes,\n\u001b[0;32m     20\u001b[0m     process_nans,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     reorder_columns,\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebscraping\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     validate_scraped_dataframes,\n\u001b[0;32m     28\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'load_scraped_data' from 'src.data_access' (e:\\OneDrive\\nba_analysis_project\\src\\data_access\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# For Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "os.chdir('..') #change to parent directory\n",
    "\n",
    "from src.data_access import (\n",
    "    load_scraped_data,\n",
    ")\n",
    "\n",
    "from src.data_processing import (\n",
    "    merge_scraped_dataframes,\n",
    "    process_nans,\n",
    "    rename_columns,\n",
    "    extract_new_columns,\n",
    "    reorder_columns,\n",
    ")\n",
    "\n",
    "from src.webscraping.utils import (\n",
    "    validate_scraped_dataframes,\n",
    ")\n",
    "\n",
    "from pathlib import Path  #for Windows/Linux compatibility\n",
    "DATAPATH = Path(r'data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\nba_analysis_project\\src\\data_access.py:20: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(DATAPATH / file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1 does not match the game ids of the first dataframe\n"
     ]
    }
   ],
   "source": [
    "# retrieve the scraped data and merge into a single joined dataframe\n",
    "\n",
    "scraped_data = [] #list of dataframes\n",
    "scraped_data = load_scraped_data()\n",
    "if len(scraped_data) == 0:\n",
    "    print('No data loaded')\n",
    "else:\n",
    "    if validate_scraped_dataframes(scraped_data):\n",
    "        games = merge_scraped_dataframes(scraped_data)\n",
    "        games.head()\n",
    "    else:\n",
    "        print(\"validation failed\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "games = pd.read_csv(DATAPATH / \"games.csv\")\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAME_ID and TEAM_ID are the primary keys, so let's put them up front\n",
    "\n",
    "col = games.pop(\"TEAM_ID\")\n",
    "games.insert(0, \"TEAM_ID\", col)\n",
    "\n",
    "col = games.pop(\"GAME_ID\")\n",
    "games.insert(0, \"GAME_ID\", col)\n",
    "\n",
    "games.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"Match Up\" column indicates which team is the home team and which is the visitor, but let's explicitly flag the home team.\n",
    "# If the \"Match Up\" column contains \"@\" then the team is the visitor, if it contains \"vs.\" then the team is the home team.\n",
    "\n",
    "games[\"HOME_TEAM\"] = games[\"Match Up\"].str.contains(\"vs.\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's move HOME_TEAM to the 3rd column\n",
    "\n",
    "col = games.pop(\"HOME_TEAM\")\n",
    "games.insert(2, \"HOME_TEAM\", col)\n",
    "\n",
    "games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert W/L column to integer\n",
    "\n",
    "games[\"WIN\"] = games[\"W/L\"].str.contains(\"W\").astype(int)\n",
    "\n",
    "# Let's move WIN to the 4th column\n",
    "\n",
    "col = games.pop(\"WIN\")\n",
    "games.insert(3, \"WIN\", col)\n",
    "\n",
    "# Drop the W/L column\n",
    "\n",
    "games = games.drop(\"W/L\", axis=1)\n",
    "\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minutes played is not really that useful of a feature in terms of a an overall team evaluation metric. It is more of a player metric. \n",
    "# It might be useful in comparing the stats from a regular length game to an overtime game, but a simple flag for overtime might be good enough.\n",
    "\n",
    "# Let's see how many games went into overtime (MIN > 240) \n",
    "\n",
    "overtimegames = games[games[\"MIN\"] > 240].shape[0]\n",
    "totalgames = games.shape[0]\n",
    "\n",
    "print(f\"Number of overtime games: {overtimegames} out of {totalgames} total games ({overtimegames/totalgames:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About 6% of games went into overtime. Not a large amount, but not super small amount either, so we will both keep MIN and set a flag for overtime games\n",
    "# This will give us more flexibility in the future since we may or may not want to include MIN in our analysis.\n",
    "\n",
    "games[\"OVERTIME\"] = (games[\"MIN\"] > 240).astype(int)\n",
    "\n",
    "# Let's move OVERTIME to the 7th column to keep it next to MIN\n",
    "\n",
    "col = games.pop(\"OVERTIME\")\n",
    "games.insert(7, \"OVERTIME\", col)\n",
    "\n",
    "\n",
    "games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first digit of the GAME_ID denotes whether the game was played in the regular season (2) or the playoffs (4) or play-in (5)\n",
    "# The second and third digits denote the season (e.g. 21 for the 2021-2022 season)\n",
    "\n",
    "# To make it easier to extract this info, first let's convert GAME_ID to a string\n",
    "\n",
    "games[\"GAME_ID\"] = games[\"GAME_ID\"].astype(str)\n",
    "\n",
    "games[\"SEASON\"] = games[\"GAME_ID\"].str[1:3].astype(int) + 2000\n",
    "\n",
    "# create flag for playoff games where the first digit of the GAME_ID is greater than 2\n",
    "games[\"PLAYOFF\"] = (games[\"GAME_ID\"].str[0].astype(int) > 2).astype(int)\n",
    "\n",
    "# Let's move SEASON to the 5th column and PLAYOFF to the 6th column\n",
    "\n",
    "col = games.pop(\"SEASON\")\n",
    "games.insert(5, \"SEASON\", col)\n",
    "\n",
    "col = games.pop(\"PLAYOFF\")\n",
    "games.insert(6, \"PLAYOFF\", col)\n",
    "\n",
    "games.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now group the columns - first the game info, then the team info, then the game stats for that team\n",
    "all_columns = games.columns.tolist()\n",
    "\n",
    "game_info = [\"GAME_ID\", \"SEASON\", \"Game Date\", \"PLAYOFF\", \"OVERTIME\", \"MIN\",]\n",
    "team_info = [\"TEAM_ID\", \"HOME_TEAM\", \"Team\", \"Match Up\"] \n",
    "team_stats = [col for col in all_columns if col not in game_info + team_info]\n",
    "\n",
    "games = games[game_info + team_info + team_stats]\n",
    "\n",
    "games.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the cleaned data\n",
    "games.to_csv(DATAPATH / \"games_cleaned.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

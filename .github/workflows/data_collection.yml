name: Data Collection (Nightly)

# This workflow is intended for the project maintainer only
# It scrapes fresh NBA data and uploads to Kaggle
# Requires secrets: KAGGLE_USERNAME, KAGGLE_KEY, PROXY_URL

on:
  schedule:
    - cron: '0 8 * * *'  # 3am EST = 8am UTC
  workflow_dispatch:  # Manual trigger

jobs:
  collect_and_publish:
    runs-on: ubuntu-latest
    # Only run on original repo, not forks (prevents errors from missing secrets)
    if: github.repository == 'cmunch1/nba_analysis_project'

    # Use the pre-built Docker image
    container:
      image: ghcr.io/${{ github.repository }}:latest
      options: --user root
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      volumes:
        - /home/runner/work/${{ github.repository }}/data:/app/data

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Kaggle credentials
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"$KAGGLE_USERNAME\",\"key\":\"$KAGGLE_KEY\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Download Existing Cumulative Data from Kaggle
        run: |
          mkdir -p data/cumulative_scraped data/processed
          # Download the existing cumulative data to merge with newly scraped data
          # Note: This assumes the dataset already exists from a previous upload
          kaggle datasets download -d ${{ secrets.KAGGLE_USERNAME }}/nba-game-team-statistics -p data --unzip || {
            echo "Warning: Could not download existing data. This is expected on first run."
            echo "Will proceed with webscraping only."
          }

      - name: Configure Proxy
        env:
          PROXY_URL: ${{ secrets.PROXY_URL }}
        run: /app/scripts/configure_proxy.sh

      - name: Debug Chromium Installation
        run: |
          echo "=== Checking Chromium Installation ==="
          which chromium || echo "chromium not in PATH"
          which chromium-browser || echo "chromium-browser not in PATH"
          ls -la /usr/bin/chromium* || echo "No chromium binaries in /usr/bin"
          echo ""
          echo "=== Chromium Version ==="
          chromium --version || echo "Failed to get chromium version"
          echo ""
          echo "=== Chromedriver Version ==="
          which chromedriver || echo "chromedriver not in PATH"
          chromedriver --version || echo "Failed to get chromedriver version"
          echo ""
          echo "=== Testing Chromium Headless ==="
          chromium --headless --no-sandbox --disable-setuid-sandbox --disable-dev-shm-usage --disable-gpu --dump-dom https://www.google.com 2>&1 | head -20 || echo "Chromium test failed"
          echo ""
          echo "=== Running as user ==="
          whoami
          id

      - name: Run Webscraping
        run: |
          export PYTHONPATH="${GITHUB_WORKSPACE}/src:${PYTHONPATH:-}"
          python -m nba_app.webscraping.main

      - name: Show ChromeDriver Log (if exists)
        if: always()
        run: |
          if [ -f /tmp/chromedriver.log ]; then
            echo "=== ChromeDriver Log ==="
            cat /tmp/chromedriver.log
          else
            echo "No ChromeDriver log found at /tmp/chromedriver.log"
          fi

      - name: Run Data Processing
        run: |
          export PYTHONPATH="${GITHUB_WORKSPACE}/src:${PYTHONPATH:-}"
          python -m nba_app.data_processing.main

      - name: Upload to Kaggle
        run: /app/scripts/upload_to_kaggle.sh

      - name: Upload logs (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs
          path: logs/
          retention-days: 7

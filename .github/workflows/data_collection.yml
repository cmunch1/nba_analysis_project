name: Data Collection (Nightly)

# This workflow is intended for the project maintainer only
# It scrapes fresh NBA data and uploads to Kaggle
# Requires secrets: KAGGLE_USERNAME, KAGGLE_KEY, PROXY_URL

on:
  schedule:
    - cron: '0 8 * * *'  # 3am EST = 8am UTC
  workflow_dispatch:  # Manual trigger

jobs:
  collect_and_publish:
    runs-on: ubuntu-latest
    # Only run on original repo, not forks (prevents errors from missing secrets)
    if: github.repository == 'cmunch1/nba_analysis_project'

    # Use the pre-built Docker image
    container:
      image: ghcr.io/${{ github.repository }}:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      volumes:
        - /home/runner/work/${{ github.repository }}/data:/app/data

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Kaggle credentials
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          mkdir -p ~/.kaggle
          echo "{\"username\":\"$KAGGLE_USERNAME\",\"key\":\"$KAGGLE_KEY\"}" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json

      - name: Download Existing Cumulative Data from Kaggle
        run: |
          mkdir -p data/cumulative_scraped data/processed
          # Download the existing cumulative data to merge with newly scraped data
          # Note: This assumes the dataset already exists from a previous upload
          kaggle datasets download -d ${{ secrets.KAGGLE_USERNAME }}/nba-game-team-statistics -p data --unzip || {
            echo "Warning: Could not download existing data. This is expected on first run."
            echo "Will proceed with webscraping only."
          }

      - name: Configure Proxy
        env:
          PROXY_URL: ${{ secrets.PROXY_URL }}
        run: /app/scripts/configure_proxy.sh

      - name: Run Webscraping
        run: uv run -m src.nba_app.webscraping.main

      - name: Run Data Processing
        run: uv run -m src.nba_app.data_processing.main

      - name: Upload to Kaggle
        run: /app/scripts/upload_to_kaggle.sh

      - name: Upload logs (on failure)
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: pipeline-logs
          path: logs/
          retention-days: 7
